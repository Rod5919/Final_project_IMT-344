{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project.ipynb","provenance":[],"authorship_tag":"ABX9TyMFMz+cK39/IV2rL/p6fzRC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5BB98u0W825D"},"source":["##People detection\n","The next function is meant to detect the people in our input video"]},{"cell_type":"code","metadata":{"id":"htUFxVaV1I58"},"source":["# base path to YOLO directory\n","MODEL_PATH = \"yolo-coco\"\n","\n","# weak detections in video by minimum probability and threshold when using maxima suppression\n","minimun_conf = 0.3\n","thresh = 0.3\n","\n","# if we want to use GPU, cuda or something like that\n","USE_GPU = False\n","\n","# the team is using pixels to determine if to people are to close together, the minimum safe distance is \n","MIN_DISTANCE = 50\n","\n","# libraries\n","import numpy as np\n","import cv2\n","\n","# funtion to detect people\n","def detect_people(frame, net_dark, layer_names, personIdx=0):\n","\n","\t# dimention of the frames\n","\t(H, W) = frame.shape[:2]\n","\tresultados = []\n","\n","\t# blobs can store images, binary data\n","\tblob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n","\tnet_dark.setInput(blob)\n","\tlayerOutputs = net_dark.forward(layer_names)\n","\n","  # making list of boxes, their centroids and condidences\n","\tboxes = []\n","\tcentroids = []\n","\tconfidences = []\n","\n","\t# loop over each of the layer outputs\n","\tfor output in layerOutputs:\n","\t\t# loop over each of the detections\n","\t\tfor detection in output:\n","      # getting to know the class ID and the scores\n","\t\t\tscores = detection[5:]\n","\t\t\tclassID = np.argmax(scores)\n","\t\t\tconfidence = scores[classID]\n","\n","      # ensuring that we are detecting a persona and having the minimum confidence\n","\t\t\tif classID == personIdx and confidence > minimun_conf:\n","\t\t\t\t\n","        # scaling the boxes that represent the detection of the people\n","\t\t\t\tbox = detection[0:4] * np.array([W, H, W, H])\n","\t\t\t\t(centerX, centerY, width, height) = box.astype(\"int\")\n","\n","        # defining top and corners of the box\n","\t\t\t\tx = int(centerX - (width / 2))\n","\t\t\t\ty = int(centerY - (height / 2))\n","\n","        # update list of boxes values, (centroids)\n","\t\t\t\tboxes.append([x, y, int(width), int(height)])\n","\t\t\t\tcentroids.append((centerX, centerY))\n","\t\t\t\tconfidences.append(float(confidence))\n","\n","  # applying non maxima suppression for weak overlapping boxes\n","\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, minimun_conf, thresh)\n","\n","\t# there must be at least one detection\n","\tif len(idxs) > 0:\n","\t\t# loop over the indexes we are keeping\n","\t\tfor i in idxs.flatten():\n","\t\t\t# extract the bounding box coordinates\n","\t\t\t(x, y) = (boxes[i][0], boxes[i][1])\n","\t\t\t(w, h) = (boxes[i][2], boxes[i][3])\n","\n","\t\t\t# update list to of the person prediction probability\n","\t\t\tr = (confidences[i], (x, y, x + w, y + h), centroids[i])\n","\t\t\tresultados.append(r)\n","\n","\t# return the list of results\n","\treturn resultados"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4KvdAk0CAW6R"},"source":["##Testing on frame\n","Testing the people detector for one frame"]},{"cell_type":"code","metadata":{"id":"vHp5gkSX2llT"},"source":["# we are using this resources\n","# https://pjreddie.com/darknet/yolo/\n","\n","#wget https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg\n","configPath = os.path.sep.join([MODEL_PATH, \"yolov3.cfg\"])\n","\n","#wget https://pjreddie.com/media/files/yolov3.weights\n","weightsPath = os.path.sep.join([MODEL_PATH, \"yolov3.weights\"])\n","\n","net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n","ln = net.getLayerNames()\n","ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n","\n","resultados = detect_people(frame, net, ln, personIdx=LABELS.index(\"person\"))"],"execution_count":null,"outputs":[]}]}